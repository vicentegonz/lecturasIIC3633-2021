# Critica Evaluating Recommendation Systems

El paper profundiza en las diferentes formas de evaluar un sistema recomendador, para esto se enfoca principalmente en dos areas. La primera es la manera en la que se puede generar un testeo, estos prueden ser online, offline(datasets) o con usuarios presenciales. cada uno de estos estilos de prueba tienen sus propias ventajas como la obtencion de informacion implicita al testear con usuarios presenciales, datos bien distribuidos y confiables al usar datasets ya creados o generar experiencias realistas para el ususario con la interfaz y el sistema mismo. La segunda area que menciona el paper son las diferentes metricas de evaluacion para un sistema, plantea tanto las ventajas y desventajas de las metricas mas comunes y a su vez da un ejemplo de como estas pueden ser aplicadas. En si encontre que el texto utiliza un lneguaje muy especifico y tecnico por lo que un lector no familiarizado con el tema no entenderia del todo ademas debido a su extencion se puede volver medio repetitivo al no variar el tema genral de la seccion que se esta leyendo.

El texto enfatiza mucho en la correcta eleccion del tipo de pruebas para un sistema recomendador, lo cual encontre interesante, ya que generalmente en la universidad solo se habla del testeo offline sin mencionar mucho los otros dos siendo que cada uno trae multiples beneficios dependiendo de lo que se quiera lograr con el sistema recomendador que se este generando. Encontre interesante que se diferenciara entre el testeo online y presencial, ya que inicialmente pense que apuntaban a la recoleccion de los mismos tipos de datos. Existen multiples desventajas en cada uno como lo caro que puede ser el generar una prueba con usuarios presenciales mas aun en un contexto de pandemia como se ha vivido estos ultimos años o lo poco descriptivo que puede ser un testeo online en cuanto a la experiencia vivida con el sistema. Seria interesante que se profundizara mas sobre estos temas y los beneficios que pueden tener al momento de estar inciando un nuevo sistema o trabajando en uno ya existente.

Otra tema que llamo la atencion a lo largo de la lectura es que en la seccion de las metricas separa en 3 diferentes areas la precision de la prediccion, estas areas son medir la precision de las predicciones, ratings y uso. Creo que generalmente se suele tomar esta metrica como un unico punto a evaluar pero realmente ¿que sentido tiene tener una precision del 100% en cuanto a prediccion o rating si el usuario final no se interesa en ellas? Es en este punto cuando entran el resto de las metricas mas complicadas de conseguir como lo son la novedad de las predicciones para encontrar nuevos temas o areas de interes, la cobertura y la confianza de las predicciones, el lograr captar la etencion de usuarios nuevos sin muchas interacciones o la inclucion de items nuevos que no han sido valorados por muchos o son nuevos en el mercado. 

En la seccion 3.5 se mensiona la metrica de Trust y algunas formas de obtenerla, la explicacion o justificacion de la prediccion me parecio una buena tecnica ya que entrega valor a la prediccion reforsandola y generando una mayor confianza en ella, pero por otro lado no estoy de acuerdo con el recomendar items que el sistema ya sabe que le gustan al usuario, porque finalmente no se le entrega absolutamente ni un valor real al usuario. Ademas en el caso que efectivamente un sistema no genere buenas predicciones se esta abusando de la informacion disponible para generar malas predicciones y una falsa confianza en el sistema lo cual a la larga solo perjudica al usuario final y al producto generado en si. Para finalizar me parecio que el texto si bien era largo y especifico me ayudo mucho a pensar en areas que no habia considerado antes (entregas de tareas o proyectos) al momento de evaluar que tan bien estaba mi sistema, ademas al tener las formulas, ventajas, desventajas y ejemplos practicos de cada uno permite visualizarlo de una manera mas facil y aplicable a tareas y proyectos futuros.